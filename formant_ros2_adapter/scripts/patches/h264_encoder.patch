--- h264_encoder.py	2023-01-10 10:29:13.068258791 -0600
+++ h264_encoder_1.py	2023-01-10 10:29:32.163823950 -0600
@@ -1,751 +1,751 @@
-#! /usr/bin/env python3
-
-from typing import Optional, Callable
-import time
-import gi
-import re
-import threading
-import math
-import subprocess
-
-gi.require_version("Gtk", "3.0")
-gi.require_version("Gst", "1.0")
-
-from gi.repository import Gst  # noqa: E402
-
-from common.appsink_pipeline import AppsinkPipeline  # noqa: E402
-from common.constant import (  # noqa: E402
-    FORMANT_ACCELERATED_VIDEO_ENCODING,
-    FORMANT_ENCODING_BITRATE,
-    FORMANT_OVERRIDE_BITRATE,
-    FORMANT_USE_RTP_JITTER_BUFFER,
-    FORMANT_VIDEO_FRAMERATE,
-    FORMANT_LOW_BANDWIDTH_BITRATE,
-    FORMANT_FLV_DECODE,
-    FORMANT_RTSP_BUFFER_LENGTH,
-    FORMANT_FORCE_ALLOW_PICAM,
-    FORMANT_RTSP_PROTOCOLS,
-    FORMANT_FORCE_ACCELERATED_VIDEO_ENCODING,
-    FORMANT_ENCODE_SPEED_PRESET,
-    FORMANT_ACCELERATED_ENCODE_SPEED_PRESET,
-)
-from common.encoded_video_telemetry_uploader import (  # noqa: E402
-    EncodedVideoTelemetryUploader,
-)
-from common.logger import get_logger, log_thread_exceptions  # noqa: E402
-from common.utils import strip_rtsp_secrets
-from common.video_configuration import (  # noqa: E402
-    LOW_BANDWIDTH_FRAMERATE,
-    VideoConfiguration,
-    get_closest_video_configuration,
-    PICAM_PIXEL_FORMATS,
-)
-
-logger = get_logger()
-
-KEYFRAME_HEX = "67"
-
-RTSP_IMAGE_TYPE = "rtsp"
-RTMP_IMAGE_TYPE = "rtmp"
-UDP_IMAGE_TYPE = "udp"
-H264_IP_IMAGE_TYPES = [RTSP_IMAGE_TYPE, UDP_IMAGE_TYPE]
-IP_IMAGE_TYPES = [RTMP_IMAGE_TYPE, RTSP_IMAGE_TYPE, UDP_IMAGE_TYPE]
-HARDWARE_IMAGE_TYPE = "hardware"
-GRPC_IMAGE_TYPE = "image"
-ROS_IMAGE_TYPE = "sensor_msgs/Image"
-ROS_COMPRESSED_IMAGE_TYPE = "sensor_msgs/CompressedImage"
-APPSRC_SOURCE_TYPES = [GRPC_IMAGE_TYPE, ROS_IMAGE_TYPE, ROS_COMPRESSED_IMAGE_TYPE]
-VALID_INPUT_TYPES = [
-    RTSP_IMAGE_TYPE,
-    RTMP_IMAGE_TYPE,
-    UDP_IMAGE_TYPE,
-    HARDWARE_IMAGE_TYPE,
-    GRPC_IMAGE_TYPE,
-    ROS_IMAGE_TYPE,
-    ROS_COMPRESSED_IMAGE_TYPE,
-]
-
-BASE_FRAMERATE = (
-    FORMANT_VIDEO_FRAMERATE  # base framerate before deriving it from the input stream
-)
-FRAMERATE_WINDOW_SECONDS = 2.5
-KEY_INT_MAX = 10
-
-ACCEPTED_H264_PROFILES = [
-    "profile=(string)constrained-baseline",
-    "profile=(string)baseline",
-]
-
-PRESETS = [
-    "None",
-    "ultrafast",
-    "superfast",
-    "veryfast",
-    "faster",
-    "fast",
-    "medium",
-    "slow",
-    "slower",
-    "veryslow",
-    "placebo",
-]
-INDEX_PRESET_MAP = {str(i): preset for i, preset in enumerate(PRESETS)}
-PRESET_MAP = {preset: preset for preset in PRESETS}
-USER_PRESET_MAP = {
-    "fastest": "ultrafast",
-    "normal": "veryfast",
-    "quality": "fast",
-    "slowest": "veryslow",
-}
-ENCODE_SPEED_PRESET = {**INDEX_PRESET_MAP, **PRESET_MAP, **USER_PRESET_MAP}.get(
-    FORMANT_ENCODE_SPEED_PRESET, "ultrafast"
-)
-
-
-class H264EncoderInputConfig:
-    @classmethod
-    def from_input_config(cls, config, ip_h264_reencode=None):
-        new_ip_h264_reencode = (
-            config.ip_h264_reencode if ip_h264_reencode is None else ip_h264_reencode
-        )
-        return cls(
-            config.source_type,
-            config.bitrate,
-            config.use_acceleration,
-            config.hw_descriptor,
-            config.ip_location,
-            new_ip_h264_reencode,
-            config.rtsp_encoding_needed,
-            config.raw_format,
-            config.compressed_format,
-            config.encoded_format,
-            config.width,
-            config.height,
-            config.quality,
-            config._aspect_ratio,
-            config.low_bandwidth_mode,
-        )
-
-    def __init__(
-        self,
-        source_type: str,
-        bitrate: int = FORMANT_ENCODING_BITRATE,
-        use_acceleration: bool = (
-            FORMANT_ACCELERATED_VIDEO_ENCODING
-            or FORMANT_FORCE_ACCELERATED_VIDEO_ENCODING
-        ),
-        hw_descriptor: Optional[str] = None,
-        ip_location: Optional[str] = None,
-        ip_h264_reencode: Optional[bool] = False,
-        rtsp_encoding_needed: Optional[bool] = None,
-        raw_format: Optional[str] = None,
-        compressed_format: Optional[str] = None,
-        encoded_format: Optional[str] = None,
-        width: Optional[int] = None,
-        height: Optional[int] = None,
-        quality: str = "passthrough",
-        aspect_ratio: Optional[str] = None,
-        low_bandwidth_mode: Optional[bool] = False,
-    ):
-        if source_type not in VALID_INPUT_TYPES:
-            raise ValueError("Unsupported h264 encoder source type.")
-        self.source_type = source_type
-
-        self.bitrate = bitrate
-        self.use_acceleration = use_acceleration and _has_accelerated_elements()
-
-        if source_type == ROS_IMAGE_TYPE and raw_format is None:
-            raise ValueError("Raw inputs must have raw_format provided")
-        self.raw_format = raw_format
-
-        if (
-            source_type in [GRPC_IMAGE_TYPE, ROS_COMPRESSED_IMAGE_TYPE]
-            and compressed_format is None
-            and encoded_format is None
-        ):
-            raise ValueError(
-                "Compressed inputs must have compressed_format or encoded_format"
-            )
-        self.compressed_format = compressed_format
-
-        if encoded_format is not None and encoded_format != "h264":
-            raise ValueError("Encoded format must be h264")
-
-        self.encoded_format = encoded_format
-        self.hw_descriptor = hw_descriptor
-        self.ip_location = ip_location
-        self.ip_h264_reencode = ip_h264_reencode
-        self.rtsp_encoding_needed = rtsp_encoding_needed
-        self.width = width
-        self.height = height
-        self.quality = quality
-        self._aspect_ratio = aspect_ratio
-        self.low_bandwidth_mode = low_bandwidth_mode
-
-        self.video_config = None
-        if self.source_type == HARDWARE_IMAGE_TYPE:
-            self.quality = quality
-            result = get_hardware_formats(self.hw_descriptor)
-            if result is not None:
-                video_configurations = VideoConfiguration.many_from_str(result)
-                if len(video_configurations) > 0:
-                    video_config = get_closest_video_configuration(
-                        self.quality,
-                        video_configurations,
-                        self._aspect_ratio,
-                        self.use_acceleration,
-                        self.low_bandwidth_mode,
-                    )
-                    self.video_config = video_config
-        if self.quality != "passthrough" and self.source_type in APPSRC_SOURCE_TYPES:
-            self.video_config = VideoConfiguration.get_default_config_for_quality(
-                self.quality,
-                self.low_bandwidth_mode,
-            )
-        if not FORMANT_OVERRIDE_BITRATE:
-            self.set_bitrate_for_config_and_quality()
-
-    def set_bitrate_for_config_and_quality(self):
-        if self.low_bandwidth_mode:
-            self.bitrate = FORMANT_LOW_BANDWIDTH_BITRATE
-            return
-        quality = self.quality
-        if quality == "passthrough":
-            return
-        video_config = self.video_config
-        if video_config is None:
-            return
-        height = (
-            video_config.height
-            if video_config.height < video_config.get_dimensions_for_quality(quality)[0]
-            else video_config.get_dimensions_for_quality(quality)[0]
-        )
-        if height >= 1080:
-            self.bitrate = 4096
-        elif height >= 720:
-            self.bitrate = 2048
-        elif height >= 480:
-            self.bitrate = 1024
-        elif height >= 360:
-            self.bitrate = 512
-        else:
-            self.bitrate = 256
-        if video_config.fps < 20 and video_config.fps > 0:
-            self.bitrate = int(self.bitrate / 2.0)
-
-    def __repr__(self):
-        if self.hw_descriptor:
-            return (
-                "Hardware Source %s, quality=%s, configuration=%s,\
-                     bitrate=%s, low_bandwidth=%s"
-                % (
-                    self.hw_descriptor,
-                    self.quality,
-                    str(self.video_config),
-                    self.bitrate,
-                    self.low_bandwidth_mode,
-                )
-            )
-        elif self.ip_location:
-            return "%s Source %s" % (
-                self.source_type.upper(),
-                strip_rtsp_secrets(self.ip_location),
-            )
-        elif self.raw_format:
-            return "Raw %s (%s x %s) %s, %s Mbps" % (
-                self.raw_format,
-                self.width,
-                self.height,
-                self.quality,
-                self.bitrate,
-            )
-        elif self.compressed_format:
-            return "Compressed %s %s %s Mbps" % (
-                self.compressed_format,
-                self.quality,
-                self.bitrate,
-            )
-        elif self.encoded_format:
-            return "Encoded %s %s %s Mbps" % (
-                self.encoded_format,
-                self.quality,
-                self.bitrate,
-            )
-
-
-class H264Encoder(AppsinkPipeline):
-    def __init__(
-        self,
-        teleop_data_produced_callback: Callable,
-        telemetry_data_produced_callback: Callable,
-        encode_for_teleop: bool,
-        encode_for_telemetry: bool,
-        input_config: H264EncoderInputConfig,
-    ):
-        self._teleop_data_produced_callback = teleop_data_produced_callback
-        self._telemetry_data_produced_callback = telemetry_data_produced_callback
-        self._encode_for_teleop = encode_for_teleop
-        self._encode_for_telemetry = encode_for_telemetry
-        self._input_config = input_config
-        self._using_appsrc = self._input_config.source_type in APPSRC_SOURCE_TYPES
-        self._telemetry_uploader = None  # type: Optional[EncodedVideoTelemetryUploader]
-
-        description = "Video pipeline: %s" % str(self._input_config)
-        super().__init__(description, self.forward_video_data)
-
-    def _reset(self):
-        super()._reset()
-        self._current_frame_index = 0  # type: int
-        self._telemetry_uploader = None
-        self._src = None
-        self._h264parse = None
-        self._jitter_buffer = None
-
-        # start at base framerate before deriving from the input stream
-        self._framerate = BASE_FRAMERATE  # type: int
-        self._frame_count_in_window = 0  # type: int
-        self._frame_window_period_seconds = FRAMERATE_WINDOW_SECONDS  # type: float
-
-        if self._input_config.use_acceleration:
-            logger.info("Using NVIDIA hardware accelerated video encoder")
-
-        if self._encode_for_telemetry:
-            if self._telemetry_uploader is not None:
-                self._telemetry_uploader.clip_now()
-            self._telemetry_uploader = EncodedVideoTelemetryUploader(
-                self._telemetry_data_produced_callback
-            )
-
-    def _restart(self, immediate=False):
-        if self._telemetry_uploader is not None:
-            self._telemetry_uploader.clip_now()
-        super()._restart(immediate)
-
-    def _handle_egress(self):
-        super()._handle_egress()
-        self._handle_rtsp_profile()
-
-    def _handle_rtsp_profile(self):
-        if not self._h264parse:
-            return
-        base_found = False
-        for pad in self._h264parse.srcpads:
-            caps = pad.get_current_caps()
-            caps_string = caps.to_string()
-            base_found = base_found or (
-                True in [x in caps_string for x in ACCEPTED_H264_PROFILES]
-            )
-        if base_found == self._input_config.ip_h264_reencode:
-            if not base_found:
-                logger.warn(
-                    "Profile: %s is not baseline or constrained-baseline profile, re-encoding is necessary"
-                    % str(self._name.lower())
-                )
-            else:
-                logger.warn(
-                    "Profile: %s is baseline or constrained-baseline profile, re-encoding is not necessary"
-                    % str(self._name.lower())
-                )
-            self._input_config = H264EncoderInputConfig.from_input_config(
-                self._input_config, ip_h264_reencode=not base_found
-            )
-            self._restart(immediate=True)
-            return
-
-    def _initalize_pipeline(self):
-        super()._initalize_pipeline()
-        if (
-            self._input_config.source_type in H264_IP_IMAGE_TYPES
-            and self._input_config.rtsp_encoding_needed is False
-        ):
-            self._h264parse = self._pipe.get_by_name("parse")
-            if FORMANT_USE_RTP_JITTER_BUFFER:
-                self._jitter_buffer = self._pipe.get_by_name("jitterbuffer")
-
-        if self._using_appsrc:
-            self._src = self._pipe.get_by_name("input")
-            self._src.set_property("format", Gst.Format.TIME)
-            self._src.set_property(
-                "caps", Gst.caps_from_string(self.generate_app_src_caps_str())
-            )
-
-    # Seconds until pipeline is considered not flowing and should be restarted
-    def _get_ensure_flowing_time(self):
-        if self._input_config.source_type in IP_IMAGE_TYPES:
-            return 20.0
-        return super()._get_ensure_flowing_time()
-
-    def start(self, received_frame=False):
-        if self._using_appsrc and not received_frame:
-            return
-        self._input_config = H264EncoderInputConfig.from_input_config(
-            self._input_config
-        )
-        if (
-            self._input_config.source_type == HARDWARE_IMAGE_TYPE
-            and self._input_config.video_config is None
-        ):
-            logger.warn(
-                "Could not find valid pixel format for %s, Retrying"
-                % self._input_config.hw_descriptor
-            )
-            self._restarting = False
-            self._restart()
-            return
-        if self._input_config.source_type != HARDWARE_IMAGE_TYPE:
-            threading.Thread(
-                target=log_thread_exceptions(self.update_framerate),
-                daemon=True,
-            ).start()
-        else:
-            if self._telemetry_uploader is not None:
-                self._telemetry_uploader.set_framerate(
-                    self._input_config.video_config.fps
-                )
-        super().start()
-
-    def update_framerate(self):
-        while not self._is_shutdown:
-            time.sleep(self._frame_window_period_seconds)
-            if self._is_shutdown:
-                return
-            self._framerate = math.ceil(
-                self._frame_count_in_window / self._frame_window_period_seconds
-            )
-            self._frame_count_in_window = 0
-
-            if self._src is not None:
-                self._src.set_property(
-                    "caps", Gst.caps_from_string(self.generate_app_src_caps_str())
-                )
-            if self._telemetry_uploader is not None:
-                self._telemetry_uploader.set_framerate(self._framerate)
-
-    # PIPELINE GENERATION
-    def _get_pipeline_string(self):
-        pipeline_str = self.generate_input_str()
-
-        if self._input_config.compressed_format:
-            pipeline_str += " ! %sdec" % self._input_config.compressed_format
-        encoder_needed = self._input_config.encoded_format is None and (
-            self._input_config.video_config is None
-            or self._input_config.video_config.pixel_format != "H264"
-        )
-        if self._input_config.source_type in H264_IP_IMAGE_TYPES:
-            encoder_needed = (
-                self._input_config.rtsp_encoding_needed
-                or self._input_config.ip_h264_reencode
-            )
-        if encoder_needed:
-            pipeline_str += " ! videoconvert ! video/x-raw"
-            if self._input_config.low_bandwidth_mode:
-                pipeline_str += (
-                    " ! videorate ! video/x-raw, framerate=%s/1"
-                    % LOW_BANDWIDTH_FRAMERATE
-                )
-            pipeline_str += " ! queue"
-            if self._input_config.use_acceleration:
-                pipeline_str += self.generate_accelerated_encoder_str()
-            else:
-                pipeline_str += self.generate_default_encoder_str()
-        pipeline_str += self.generate_output_str()
-        return pipeline_str
-
-    def generate_app_src_caps_str(self) -> str:
-        app_src_caps_str = None
-        if self._input_config.source_type == ROS_IMAGE_TYPE:
-            app_src_caps_str = (
-                "video/x-raw, format=(string)%s, width=%s, height=%s, framerate=%s/1"
-                % (
-                    self._input_config.raw_format,
-                    self._input_config.width,
-                    self._input_config.height,
-                    self._framerate,
-                )
-            )
-        elif self._input_config.source_type in [
-            ROS_COMPRESSED_IMAGE_TYPE,
-            GRPC_IMAGE_TYPE,
-        ]:
-            if self._input_config.encoded_format is not None:
-                app_src_caps_str = "video/x-%s" % self._input_config.encoded_format
-            elif self._input_config.compressed_format is not None:
-                # TODO: investigate why setting the "framerate" cap
-                # causes keyframe issues with compressed image inputs
-                # in the meantime not setting "framerate" seems to have no issues
-                app_src_caps_str = "image/%s, framerate=%s/1" % (
-                    self._input_config.compressed_format,
-                    self._framerate,
-                )
-            else:
-                raise ValueError("No valid format provided for ROS/GRPC image")
-        else:
-            raise ValueError("input type must be one of: %s" % VALID_INPUT_TYPES)
-        return app_src_caps_str
-
-    def generate_accelerated_encoder_str(self) -> str:
-        interval_option = "iframeinterval"
-        if _nvv4l2h264enc_has_idrinterval():
-            interval_option = "idrinterval"
-
-        accel_bitrate = _convert_bitrate_for_jetson(self._input_config.bitrate)
-
-        accelerated_encoder_str = " ! nvvidconv"
-        accelerated_encoder_str += " ! video/x-raw(memory:NVMM), format=NV12"
-        accelerated_encoder_str += (
-            " ! nvv4l2h264enc insert-sps-pps=true insert-vui=true insert-aud=true"
-        )
-        accelerated_encoder_str += " %s=%s" % (interval_option, KEY_INT_MAX)
-        accelerated_encoder_str += " preset-level=%s bitrate=%s" % (
-            FORMANT_ACCELERATED_ENCODE_SPEED_PRESET,
-            accel_bitrate,
-        )
-
-        return accelerated_encoder_str
-
-    def generate_default_encoder_str(self) -> str:
-        default_encoder_str = (
-            " ! x264enc bitrate=%s byte-stream=true" % self._input_config.bitrate
-        )
-        default_encoder_str += " speed-preset=%s tune=zerolatency" % ENCODE_SPEED_PRESET
-        default_encoder_str += " sliced-threads=true key-int-max=%s" % KEY_INT_MAX
-        return default_encoder_str
-
-    def generate_output_str(self):
-        output_str = " ! h264parse disable-passthrough=true config-interval=-1"
-        output_str += " ! video/x-h264,"
-        if (
-            self._input_config.source_type not in H264_IP_IMAGE_TYPES
-            or self._input_config.ip_h264_reencode
-            or self._input_config.rtsp_encoding_needed
-        ):
-            output_str += " profile=constrained-baseline,"
-        output_str += " stream-format=byte-stream, alignment=au"
-        output_str += " ! appsink name=output emit-signals=true"
-        return output_str
-
-    def generate_ip_input_str(self):
-        source_type = self._input_config.source_type
-        if source_type not in IP_IMAGE_TYPES:
-            raise ValueError("IP input type must be one of: %s" % IP_IMAGE_TYPES)
-
-        input_str = "%ssrc" % source_type
-
-        if source_type == RTSP_IMAGE_TYPE:
-            input_str += ' location="%s" protocols=%s latency=%s' % (
-                self._input_config.ip_location,
-                str(FORMANT_RTSP_PROTOCOLS),
-                str(FORMANT_RTSP_BUFFER_LENGTH),
-            )
-        elif source_type == UDP_IMAGE_TYPE:
-            input_str += (
-                ' uri="%s" ! application/x-rtp' % self._input_config.ip_location
-            )
-        elif source_type == RTMP_IMAGE_TYPE:
-            input_str += ' location="%s live=1"' % self._input_config.ip_location
-
-        if source_type in H264_IP_IMAGE_TYPES:
-            if FORMANT_USE_RTP_JITTER_BUFFER:
-                input_str += " ! rtpjitterbuffer name=jitterbuffer"
-            input_str += " ! rtph264depay"
-
-        if self._input_config.rtsp_encoding_needed or (
-            source_type == RTMP_IMAGE_TYPE and not FORMANT_FLV_DECODE
-        ):
-            input_str += " ! decodebin"
-        elif source_type == RTMP_IMAGE_TYPE and FORMANT_FLV_DECODE:
-            input_str += " ! flvdemux name=demux"
-            input_str += " demux.audio ! queue ! fakesink"
-            input_str += " demux.video ! queue ! h264parse ! avdec_h264"
-
-        else:
-            input_str += " ! h264parse name=parse"
-            if self._input_config.ip_h264_reencode:
-                if self._input_config.use_acceleration:
-                    input_str += " ! omxh264dec"
-                else:
-                    input_str += " ! avdec_h264"
-        return input_str
-
-    def generate_device_input_str(self):
-        # use hardware source instead of appsrc
-        hw_descriptor = self._input_config.hw_descriptor
-        use_acceleration = self._input_config.use_acceleration
-        src = "v4l2src"
-        if hw_descriptor is not None and hw_descriptor != "":
-            src += ' device="%s"' % hw_descriptor
-
-        video_config = self._input_config.video_config
-        if video_config is None:
-            logger.warn(
-                "No compatible pixel formats found for video source: %s" % hw_descriptor
-            )
-            return src
-
-        if video_config.pixel_format in PICAM_PIXEL_FORMATS:
-            if use_acceleration or FORMANT_FORCE_ALLOW_PICAM:
-                src = "nvarguscamerasrc"
-            else:
-                logger.warn(
-                    "Cannot use pixel format: %s, not on raspi or jetson platform"
-                    % video_config.pixel_format
-                )
-                return src
-        src += (
-            video_config.to_caps(use_acceleration)
-            + video_config.decode_elements(use_acceleration)
-            + video_config.scale_to(self._input_config.quality, use_acceleration)
-        )
-        return src
-
-    def generate_input_str(self) -> str:
-        if self._using_appsrc:
-            app_src_str = "appsrc name=input stream-type=0 is-live=true"
-            if self._input_config.encoded_format is not None:
-                app_src_str += (
-                    " ! %sparse config-interval=-1" % self._input_config.encoded_format
-                )
-            return app_src_str
-        if self._input_config.source_type in IP_IMAGE_TYPES:
-            return self.generate_ip_input_str()
-        return self.generate_device_input_str()
-
-    def _report_jitter_buffer_stats(self):
-        if self._current_frame_index % 30 == 0:
-            struct = self._jitter_buffer.get_property("stats")
-            arr = [
-                # "num-pushed",
-                "num-lost",
-                "num-late",
-                "num-duplicates",
-                # "avg-jitter",
-                "rtx-count",
-                "rtx-success-count",
-                "rtx-rtt",
-            ]
-            for v in arr:
-                result = struct.get_uint64(v)[1]
-                if result > 0:
-                    logger.info("Jitter: %s  %s=%s" % (self._name.lower(), v, result))
-
-    def forward_video_data(self, data: bytes, is_delta: bool):
-        if self._input_config.source_type in IP_IMAGE_TYPES:
-            self._frame_count_in_window += 1
-            if FORMANT_USE_RTP_JITTER_BUFFER:
-                self._report_jitter_buffer_stats()
-        index = self._current_frame_index
-        # 0: post-initialization fmp4 frame
-        # 1: fmp4 initialization segment
-        # 2: bytestream access unit
-        # 3: keyframe
-        is__idr_frame = data[10:11].hex() == KEYFRAME_HEX
-        is_keyframe = is__idr_frame or not is_delta
-        flags = 3 if is_keyframe else 2
-        self._current_frame_index += 1
-
-        if self._encode_for_teleop:
-            self._teleop_data_produced_callback(data, index, flags)
-        if self._telemetry_uploader is not None:
-            self._telemetry_uploader.receive_video_data(data, is__idr_frame)
-
-    def forward_audio_data(self, data: bytes):
-        if self._telemetry_uploader is not None:
-            self._telemetry_uploader.receive_audio_data(data)
-
-    # APPSRC SUPPORT
-    def feed_image_buffer(self, buf: bytes):
-        if not self._using_appsrc:
-            raise ValueError("Cannot feed_image_buffer: not using appsrc")
-        if not self._is_started:
-            self.start(received_frame=True)
-        if self._is_shutdown:
-            logger.debug("Fed image buffer after encoder is shut down")
-            return
-        if buf == b"":
-            logger.warn("Media encoder received empty buffer")
-            return
-        if (self._loop is not None) and (not self._loop.is_running()):
-            logger.debug("Fed image buffer before loop is running")
-            return
-        if self._pipe is None:
-            logger.debug("Fed image buffer before pipe was created")
-            return
-        if self._src is None:
-            logger.debug("Fed image buffer before src element was created")
-            return
-        if not self._using_appsrc:
-            logger.warn(
-                "feed_image_buffer called on encoder with hardware or rtsp source"
-            )
-            return
-
-        self._frame_count_in_window += 1
-        gst_buf = Gst.Buffer.new_wrapped(buf)
-        if self._pipe.current_state == Gst.State.PLAYING:
-            # Timestamp info can only be collected once frames are already incoming
-            timestamp = self._pipe.get_clock().get_time() - self._pipe.base_time
-            gst_buf.pts = timestamp
-            gst_buf.dts = timestamp
-        self._src.emit("push-buffer", gst_buf)
-
-    # AUDIO SUPPORT
-    def is_audio_setup(self):
-        if self._telemetry_uploader is None:
-            return True
-        return self._telemetry_uploader.is_audio_setup()
-
-    def setup_audio(self, format_string=None, num_channels=None, sample_rate=None):
-        if self._telemetry_uploader is not None:
-            self._telemetry_uploader.setup_audio(
-                format_string=format_string,
-                num_channels=num_channels,
-                sample_rate=sample_rate,
-            )
-
-    def get_aspect_ratio(self):
-        if self._input_config.video_config is None:
-            return None
-        return self._input_config.video_config.get_aspect_ratio()
-
-
-def _has_accelerated_elements() -> bool:
-    for _ in ["nvvidconv", "nvv4l2h264enc"]:
-        try:
-            subprocess.check_call(["gst-inspect-1.0", _])
-        except subprocess.CalledProcessError as e:
-            if e.returncode == 255:
-                return False
-    return True
-
-
-def _convert_bitrate_for_jetson(bitrate: int) -> int:
-    if bitrate < 512:
-        b = bitrate // 10
-        return b * 10000
-    b = bitrate // 100
-    return b * 100000
-
-
-def _nvv4l2h264enc_has_idrinterval() -> bool:
-    try:
-        result = subprocess.check_output(["gst-inspect-1.0", "nvv4l2h264enc"])
-        print(str(result))
-        if "idrinterval" in str(result):
-            return True
-    except subprocess.CalledProcessError as e:
-        if e.returncode == 255:
-            return False
-    return False
-
-
-def get_hardware_formats(hw_descriptor: Optional[str]) -> Optional[str]:
-    if hw_descriptor is None:
-        return None
-    try:
-        return str(
-            subprocess.check_output(
-                ["v4l2-ctl", "-d", hw_descriptor, "--list-formats-ext"]
-            )
-        )
-    except Exception:
-        return None
+#! /usr/bin/env python3
+
+from typing import Optional, Callable
+import time
+import gi
+import re
+import threading
+import math
+import subprocess
+
+gi.require_version("Gtk", "3.0")
+gi.require_version("Gst", "1.0")
+
+from gi.repository import Gst  # noqa: E402
+
+from common.appsink_pipeline import AppsinkPipeline  # noqa: E402
+from common.constant import (  # noqa: E402
+    FORMANT_ACCELERATED_VIDEO_ENCODING,
+    FORMANT_ENCODING_BITRATE,
+    FORMANT_OVERRIDE_BITRATE,
+    FORMANT_USE_RTP_JITTER_BUFFER,
+    FORMANT_VIDEO_FRAMERATE,
+    FORMANT_LOW_BANDWIDTH_BITRATE,
+    FORMANT_FLV_DECODE,
+    FORMANT_RTSP_BUFFER_LENGTH,
+    FORMANT_FORCE_ALLOW_PICAM,
+    FORMANT_RTSP_PROTOCOLS,
+    FORMANT_FORCE_ACCELERATED_VIDEO_ENCODING,
+    FORMANT_ENCODE_SPEED_PRESET,
+    FORMANT_ACCELERATED_ENCODE_SPEED_PRESET,
+)
+from common.encoded_video_telemetry_uploader import (  # noqa: E402
+    EncodedVideoTelemetryUploader,
+)
+from common.logger import get_logger, log_thread_exceptions  # noqa: E402
+from common.utils import strip_rtsp_secrets
+from common.video_configuration import (  # noqa: E402
+    LOW_BANDWIDTH_FRAMERATE,
+    VideoConfiguration,
+    get_closest_video_configuration,
+    PICAM_PIXEL_FORMATS,
+)
+
+logger = get_logger()
+
+KEYFRAME_HEX = "67"
+
+RTSP_IMAGE_TYPE = "rtsp"
+RTMP_IMAGE_TYPE = "rtmp"
+UDP_IMAGE_TYPE = "udp"
+H264_IP_IMAGE_TYPES = [RTSP_IMAGE_TYPE, UDP_IMAGE_TYPE]
+IP_IMAGE_TYPES = [RTMP_IMAGE_TYPE, RTSP_IMAGE_TYPE, UDP_IMAGE_TYPE]
+HARDWARE_IMAGE_TYPE = "hardware"
+GRPC_IMAGE_TYPE = "image"
+ROS_IMAGE_TYPE = "sensor_msgs/Image"
+ROS_COMPRESSED_IMAGE_TYPE = "sensor_msgs/CompressedImage"
+APPSRC_SOURCE_TYPES = [GRPC_IMAGE_TYPE, ROS_IMAGE_TYPE, ROS_COMPRESSED_IMAGE_TYPE]
+VALID_INPUT_TYPES = [
+    RTSP_IMAGE_TYPE,
+    RTMP_IMAGE_TYPE,
+    UDP_IMAGE_TYPE,
+    HARDWARE_IMAGE_TYPE,
+    GRPC_IMAGE_TYPE,
+    ROS_IMAGE_TYPE,
+    ROS_COMPRESSED_IMAGE_TYPE,
+]
+
+BASE_FRAMERATE = (
+    FORMANT_VIDEO_FRAMERATE  # base framerate before deriving it from the input stream
+)
+FRAMERATE_WINDOW_SECONDS = 2.5
+KEY_INT_MAX = 10
+
+ACCEPTED_H264_PROFILES = [
+    "profile=(string)constrained-baseline",
+    "profile=(string)baseline",
+]
+
+PRESETS = [
+    "None",
+    "ultrafast",
+    "superfast",
+    "veryfast",
+    "faster",
+    "fast",
+    "medium",
+    "slow",
+    "slower",
+    "veryslow",
+    "placebo",
+]
+INDEX_PRESET_MAP = {str(i): preset for i, preset in enumerate(PRESETS)}
+PRESET_MAP = {preset: preset for preset in PRESETS}
+USER_PRESET_MAP = {
+    "fastest": "ultrafast",
+    "normal": "veryfast",
+    "quality": "fast",
+    "slowest": "veryslow",
+}
+ENCODE_SPEED_PRESET = {**INDEX_PRESET_MAP, **PRESET_MAP, **USER_PRESET_MAP}.get(
+    FORMANT_ENCODE_SPEED_PRESET, "ultrafast"
+)
+
+
+class H264EncoderInputConfig:
+    @classmethod
+    def from_input_config(cls, config, ip_h264_reencode=None):
+        new_ip_h264_reencode = (
+            config.ip_h264_reencode if ip_h264_reencode is None else ip_h264_reencode
+        )
+        return cls(
+            config.source_type,
+            config.bitrate,
+            config.use_acceleration,
+            config.hw_descriptor,
+            config.ip_location,
+            new_ip_h264_reencode,
+            config.rtsp_encoding_needed,
+            config.raw_format,
+            config.compressed_format,
+            config.encoded_format,
+            config.width,
+            config.height,
+            config.quality,
+            config._aspect_ratio,
+            config.low_bandwidth_mode,
+        )
+
+    def __init__(
+        self,
+        source_type: str,
+        bitrate: int = FORMANT_ENCODING_BITRATE,
+        use_acceleration: bool = (
+            FORMANT_ACCELERATED_VIDEO_ENCODING
+            or FORMANT_FORCE_ACCELERATED_VIDEO_ENCODING
+        ),
+        hw_descriptor: Optional[str] = None,
+        ip_location: Optional[str] = None,
+        ip_h264_reencode: Optional[bool] = False,
+        rtsp_encoding_needed: Optional[bool] = None,
+        raw_format: Optional[str] = None,
+        compressed_format: Optional[str] = None,
+        encoded_format: Optional[str] = None,
+        width: Optional[int] = None,
+        height: Optional[int] = None,
+        quality: str = "passthrough",
+        aspect_ratio: Optional[str] = None,
+        low_bandwidth_mode: Optional[bool] = False,
+    ):
+        if source_type not in VALID_INPUT_TYPES:
+            raise ValueError("Unsupported h264 encoder source type.")
+        self.source_type = source_type
+
+        self.bitrate = bitrate
+        self.use_acceleration = use_acceleration and _has_accelerated_elements()
+
+        if source_type == ROS_IMAGE_TYPE and raw_format is None:
+            raise ValueError("Raw inputs must have raw_format provided")
+        self.raw_format = raw_format
+
+        if (
+            source_type in [GRPC_IMAGE_TYPE, ROS_COMPRESSED_IMAGE_TYPE]
+            and compressed_format is None
+            and encoded_format is None
+        ):
+            raise ValueError(
+                "Compressed inputs must have compressed_format or encoded_format"
+            )
+        self.compressed_format = compressed_format
+
+        if encoded_format is not None and encoded_format != "h264":
+            raise ValueError("Encoded format must be h264")
+
+        self.encoded_format = encoded_format
+        self.hw_descriptor = hw_descriptor
+        self.ip_location = ip_location
+        self.ip_h264_reencode = ip_h264_reencode
+        self.rtsp_encoding_needed = rtsp_encoding_needed
+        self.width = width
+        self.height = height
+        self.quality = quality
+        self._aspect_ratio = aspect_ratio
+        self.low_bandwidth_mode = low_bandwidth_mode
+
+        self.video_config = None
+        if self.source_type == HARDWARE_IMAGE_TYPE:
+            self.quality = quality
+            result = get_hardware_formats(self.hw_descriptor)
+            if result is not None:
+                video_configurations = VideoConfiguration.many_from_str(result)
+                if len(video_configurations) > 0:
+                    video_config = get_closest_video_configuration(
+                        self.quality,
+                        video_configurations,
+                        self._aspect_ratio,
+                        self.use_acceleration,
+                        self.low_bandwidth_mode,
+                    )
+                    self.video_config = video_config
+        if self.quality != "passthrough" and self.source_type in APPSRC_SOURCE_TYPES:
+            self.video_config = VideoConfiguration.get_default_config_for_quality(
+                self.quality,
+                self.low_bandwidth_mode,
+            )
+        if not FORMANT_OVERRIDE_BITRATE:
+            self.set_bitrate_for_config_and_quality()
+
+    def set_bitrate_for_config_and_quality(self):
+        if self.low_bandwidth_mode:
+            self.bitrate = FORMANT_LOW_BANDWIDTH_BITRATE
+            return
+        quality = self.quality
+        if quality == "passthrough":
+            return
+        video_config = self.video_config
+        if video_config is None:
+            return
+        height = (
+            video_config.height
+            if video_config.height < video_config.get_dimensions_for_quality(quality)[0]
+            else video_config.get_dimensions_for_quality(quality)[0]
+        )
+        if height >= 1080:
+            self.bitrate = 4096
+        elif height >= 720:
+            self.bitrate = 2048
+        elif height >= 480:
+            self.bitrate = 1024
+        elif height >= 360:
+            self.bitrate = 512
+        else:
+            self.bitrate = 256
+        if video_config.fps < 20 and video_config.fps > 0:
+            self.bitrate = int(self.bitrate / 2.0)
+
+    def __repr__(self):
+        if self.hw_descriptor:
+            return (
+                "Hardware Source %s, quality=%s, configuration=%s,\
+                     bitrate=%s, low_bandwidth=%s"
+                % (
+                    self.hw_descriptor,
+                    self.quality,
+                    str(self.video_config),
+                    self.bitrate,
+                    self.low_bandwidth_mode,
+                )
+            )
+        elif self.ip_location:
+            return "%s Source %s" % (
+                self.source_type.upper(),
+                strip_rtsp_secrets(self.ip_location),
+            )
+        elif self.raw_format:
+            return "Raw %s (%s x %s) %s, %s Mbps" % (
+                self.raw_format,
+                self.width,
+                self.height,
+                self.quality,
+                self.bitrate,
+            )
+        elif self.compressed_format:
+            return "Compressed %s %s %s Mbps" % (
+                self.compressed_format,
+                self.quality,
+                self.bitrate,
+            )
+        elif self.encoded_format:
+            return "Encoded %s %s %s Mbps" % (
+                self.encoded_format,
+                self.quality,
+                self.bitrate,
+            )
+
+
+class H264Encoder(AppsinkPipeline):
+    def __init__(
+        self,
+        teleop_data_produced_callback: Callable,
+        telemetry_data_produced_callback: Callable,
+        encode_for_teleop: bool,
+        encode_for_telemetry: bool,
+        input_config: H264EncoderInputConfig,
+    ):
+        self._teleop_data_produced_callback = teleop_data_produced_callback
+        self._telemetry_data_produced_callback = telemetry_data_produced_callback
+        self._encode_for_teleop = encode_for_teleop
+        self._encode_for_telemetry = encode_for_telemetry
+        self._input_config = input_config
+        self._using_appsrc = self._input_config.source_type in APPSRC_SOURCE_TYPES
+        self._telemetry_uploader = None  # type: Optional[EncodedVideoTelemetryUploader]
+
+        description = "Video pipeline: %s" % str(self._input_config)
+        super().__init__(description, self.forward_video_data)
+
+    def _reset(self):
+        super()._reset()
+        self._current_frame_index = 0  # type: int
+        self._telemetry_uploader = None
+        self._src = None
+        self._h264parse = None
+        self._jitter_buffer = None
+
+        # start at base framerate before deriving from the input stream
+        self._framerate = BASE_FRAMERATE  # type: int
+        self._frame_count_in_window = 0  # type: int
+        self._frame_window_period_seconds = FRAMERATE_WINDOW_SECONDS  # type: float
+
+        if self._input_config.use_acceleration:
+            logger.info("Using NVIDIA hardware accelerated video encoder")
+
+        if self._encode_for_telemetry:
+            if self._telemetry_uploader is not None:
+                self._telemetry_uploader.clip_now()
+            self._telemetry_uploader = EncodedVideoTelemetryUploader(
+                self._telemetry_data_produced_callback
+            )
+
+    def _restart(self, immediate=False):
+        if self._telemetry_uploader is not None:
+            self._telemetry_uploader.clip_now()
+        super()._restart(immediate)
+
+    def _handle_egress(self):
+        super()._handle_egress()
+        self._handle_rtsp_profile()
+
+    def _handle_rtsp_profile(self):
+        if not self._h264parse:
+            return
+        base_found = False
+        for pad in self._h264parse.srcpads:
+            caps = pad.get_current_caps()
+            caps_string = caps.to_string()
+            base_found = base_found or (
+                True in [x in caps_string for x in ACCEPTED_H264_PROFILES]
+            )
+        if base_found == self._input_config.ip_h264_reencode:
+            if not base_found:
+                logger.warn(
+                    "Profile: %s is not baseline or constrained-baseline profile, re-encoding is necessary"
+                    % str(self._name.lower())
+                )
+            else:
+                logger.warn(
+                    "Profile: %s is baseline or constrained-baseline profile, re-encoding is not necessary"
+                    % str(self._name.lower())
+                )
+            self._input_config = H264EncoderInputConfig.from_input_config(
+                self._input_config, ip_h264_reencode=not base_found
+            )
+            self._restart(immediate=True)
+            return
+
+    def _initalize_pipeline(self):
+        super()._initalize_pipeline()
+        if (
+            self._input_config.source_type in H264_IP_IMAGE_TYPES
+            and self._input_config.rtsp_encoding_needed is False
+        ):
+            self._h264parse = self._pipe.get_by_name("parse")
+            if FORMANT_USE_RTP_JITTER_BUFFER:
+                self._jitter_buffer = self._pipe.get_by_name("jitterbuffer")
+
+        if self._using_appsrc:
+            self._src = self._pipe.get_by_name("input")
+            self._src.set_property("format", Gst.Format.TIME)
+            self._src.set_property(
+                "caps", Gst.caps_from_string(self.generate_app_src_caps_str())
+            )
+
+    # Seconds until pipeline is considered not flowing and should be restarted
+    def _get_ensure_flowing_time(self):
+        if self._input_config.source_type in IP_IMAGE_TYPES:
+            return 20.0
+        return super()._get_ensure_flowing_time()
+
+    def start(self, received_frame=False):
+        if self._using_appsrc and not received_frame:
+            return
+        self._input_config = H264EncoderInputConfig.from_input_config(
+            self._input_config
+        )
+        if (
+            self._input_config.source_type == HARDWARE_IMAGE_TYPE
+            and self._input_config.video_config is None
+        ):
+            logger.warn(
+                "Could not find valid pixel format for %s, Retrying"
+                % self._input_config.hw_descriptor
+            )
+            self._restarting = False
+            self._restart()
+            return
+        if self._input_config.source_type != HARDWARE_IMAGE_TYPE:
+            threading.Thread(
+                target=log_thread_exceptions(self.update_framerate),
+                daemon=True,
+            ).start()
+        else:
+            if self._telemetry_uploader is not None:
+                self._telemetry_uploader.set_framerate(
+                    self._input_config.video_config.fps
+                )
+        super().start()
+
+    def update_framerate(self):
+        while not self._is_shutdown:
+            time.sleep(self._frame_window_period_seconds)
+            if self._is_shutdown:
+                return
+            self._framerate = math.ceil(
+                self._frame_count_in_window / self._frame_window_period_seconds
+            )
+            self._frame_count_in_window = 0
+
+            if self._src is not None:
+                self._src.set_property(
+                    "caps", Gst.caps_from_string(self.generate_app_src_caps_str())
+                )
+            if self._telemetry_uploader is not None:
+                self._telemetry_uploader.set_framerate(self._framerate)
+
+    # PIPELINE GENERATION
+    def _get_pipeline_string(self):
+        pipeline_str = self.generate_input_str()
+
+        if self._input_config.compressed_format:
+            pipeline_str += " ! %sdec" % self._input_config.compressed_format
+        encoder_needed = self._input_config.encoded_format is None and (
+            self._input_config.video_config is None
+            or self._input_config.video_config.pixel_format != "H264"
+        )
+        if self._input_config.source_type in H264_IP_IMAGE_TYPES:
+            encoder_needed = (
+                self._input_config.rtsp_encoding_needed
+                or self._input_config.ip_h264_reencode
+            )
+        if encoder_needed:
+            pipeline_str += " ! videoconvert ! video/x-raw"
+            if self._input_config.low_bandwidth_mode:
+                pipeline_str += (
+                    " ! videorate ! video/x-raw, framerate=%s/1"
+                    % LOW_BANDWIDTH_FRAMERATE
+                )
+            pipeline_str += " ! queue"
+            if self._input_config.use_acceleration:
+                pipeline_str += self.generate_accelerated_encoder_str()
+            else:
+                pipeline_str += self.generate_default_encoder_str()
+        pipeline_str += self.generate_output_str()
+        return pipeline_str
+
+    def generate_app_src_caps_str(self) -> str:
+        app_src_caps_str = None
+        if self._input_config.source_type == ROS_IMAGE_TYPE:
+            app_src_caps_str = (
+                "video/x-raw, format=(string)%s, width=%s, height=%s, framerate=%s/1"
+                % (
+                    self._input_config.raw_format,
+                    self._input_config.width,
+                    self._input_config.height,
+                    self._framerate,
+                )
+            )
+        elif self._input_config.source_type in [
+            ROS_COMPRESSED_IMAGE_TYPE,
+            GRPC_IMAGE_TYPE,
+        ]:
+            if self._input_config.encoded_format is not None:
+                app_src_caps_str = "video/x-%s" % self._input_config.encoded_format
+            elif self._input_config.compressed_format is not None:
+                # TODO: investigate why setting the "framerate" cap
+                # causes keyframe issues with compressed image inputs
+                # in the meantime not setting "framerate" seems to have no issues
+                app_src_caps_str = "image/%s, framerate=%s/1" % (
+                    self._input_config.compressed_format,
+                    self._framerate,
+                )
+            else:
+                raise ValueError("No valid format provided for ROS/GRPC image")
+        else:
+            raise ValueError("input type must be one of: %s" % VALID_INPUT_TYPES)
+        return app_src_caps_str
+
+    def generate_accelerated_encoder_str(self) -> str:
+        interval_option = "iframeinterval"
+        if _nvv4l2h264enc_has_idrinterval():
+            interval_option = "idrinterval"
+
+        accel_bitrate = _convert_bitrate_for_jetson(self._input_config.bitrate)
+
+        accelerated_encoder_str = " ! nvvidconv"
+        accelerated_encoder_str += " ! video/x-raw(memory:NVMM), format=NV12"
+        accelerated_encoder_str += (
+            " ! nvv4l2h264enc insert-sps-pps=true insert-vui=true insert-aud=true"
+        )
+        accelerated_encoder_str += " %s=%s" % (interval_option, KEY_INT_MAX)
+        accelerated_encoder_str += " preset-level=%s bitrate=%s" % (
+            FORMANT_ACCELERATED_ENCODE_SPEED_PRESET,
+            accel_bitrate,
+        )
+
+        return accelerated_encoder_str
+
+    def generate_default_encoder_str(self) -> str:
+        default_encoder_str = (
+            " ! x264enc bitrate=%s byte-stream=true" % self._input_config.bitrate
+        )
+        default_encoder_str += " speed-preset=%s tune=zerolatency" % ENCODE_SPEED_PRESET
+        default_encoder_str += " sliced-threads=true key-int-max=%s" % KEY_INT_MAX
+        return default_encoder_str
+
+    def generate_output_str(self):
+        output_str = " ! h264parse disable-passthrough=true config-interval=-1"
+        output_str += " ! video/x-h264,"
+        if (
+            self._input_config.source_type not in H264_IP_IMAGE_TYPES
+            or self._input_config.ip_h264_reencode
+            or self._input_config.rtsp_encoding_needed
+        ):
+            output_str += " profile=constrained-baseline,"
+        output_str += " stream-format=byte-stream, alignment=au"
+        output_str += " ! appsink name=output emit-signals=true"
+        return output_str
+
+    def generate_ip_input_str(self):
+        source_type = self._input_config.source_type
+        if source_type not in IP_IMAGE_TYPES:
+            raise ValueError("IP input type must be one of: %s" % IP_IMAGE_TYPES)
+
+        input_str = "%ssrc" % source_type
+
+        if source_type == RTSP_IMAGE_TYPE:
+            input_str += ' location="%s" protocols=%s latency=%s' % (
+                self._input_config.ip_location,
+                str(FORMANT_RTSP_PROTOCOLS),
+                str(FORMANT_RTSP_BUFFER_LENGTH),
+            )
+        elif source_type == UDP_IMAGE_TYPE:
+            input_str += (
+                ' uri="%s" ! application/x-rtp' % self._input_config.ip_location
+            )
+        elif source_type == RTMP_IMAGE_TYPE:
+            input_str += ' location="%s live=1"' % self._input_config.ip_location
+
+        if source_type in H264_IP_IMAGE_TYPES:
+            if FORMANT_USE_RTP_JITTER_BUFFER:
+                input_str += " ! rtpjitterbuffer name=jitterbuffer"
+            input_str += " ! rtph264depay"
+
+        if self._input_config.rtsp_encoding_needed or (
+            source_type == RTMP_IMAGE_TYPE and not FORMANT_FLV_DECODE
+        ):
+            input_str += " ! decodebin"
+        elif source_type == RTMP_IMAGE_TYPE and FORMANT_FLV_DECODE:
+            input_str += " ! flvdemux name=demux"
+            input_str += " demux.audio ! queue ! fakesink"
+            input_str += " demux.video ! queue ! h264parse ! avdec_h264"
+
+        else:
+            input_str += " ! h264parse name=parse"
+            if self._input_config.ip_h264_reencode:
+                if self._input_config.use_acceleration:
+                    input_str += " ! omxh264dec"
+                else:
+                    input_str += " ! avdec_h264"
+        return input_str
+
+    def generate_device_input_str(self):
+        # use hardware source instead of appsrc
+        hw_descriptor = self._input_config.hw_descriptor
+        use_acceleration = self._input_config.use_acceleration
+        src = "v4l2src"
+        if hw_descriptor is not None and hw_descriptor != "":
+            src += ' device="%s"' % hw_descriptor
+
+        video_config = self._input_config.video_config
+        if video_config is None:
+            logger.warn(
+                "No compatible pixel formats found for video source: %s" % hw_descriptor
+            )
+            return src
+
+        if video_config.pixel_format in PICAM_PIXEL_FORMATS:
+            if use_acceleration or FORMANT_FORCE_ALLOW_PICAM:
+                src = "nvarguscamerasrc"
+            else:
+                logger.warn(
+                    "Cannot use pixel format: %s, not on raspi or jetson platform"
+                    % video_config.pixel_format
+                )
+                return src
+        src += (
+            video_config.to_caps(use_acceleration)
+            + video_config.decode_elements(use_acceleration)
+            + video_config.scale_to(self._input_config.quality, use_acceleration)
+        )
+        return src
+
+    def generate_input_str(self) -> str:
+        if self._using_appsrc:
+            app_src_str = "appsrc name=input stream-type=0 is-live=true"
+            if self._input_config.encoded_format is not None:
+                app_src_str += (
+                    " ! %sparse config-interval=-1" % self._input_config.encoded_format
+                )
+            return app_src_str
+        if self._input_config.source_type in IP_IMAGE_TYPES:
+            return self.generate_ip_input_str()
+        return self.generate_device_input_str()
+
+    def _report_jitter_buffer_stats(self):
+        if self._current_frame_index % 30 == 0:
+            struct = self._jitter_buffer.get_property("stats")
+            arr = [
+                # "num-pushed",
+                "num-lost",
+                "num-late",
+                "num-duplicates",
+                # "avg-jitter",
+                "rtx-count",
+                "rtx-success-count",
+                "rtx-rtt",
+            ]
+            for v in arr:
+                result = struct.get_uint64(v)[1]
+                if result > 0:
+                    logger.info("Jitter: %s  %s=%s" % (self._name.lower(), v, result))
+
+    def forward_video_data(self, data: bytes, is_delta: bool):
+        if self._input_config.source_type in IP_IMAGE_TYPES:
+            self._frame_count_in_window += 1
+            if FORMANT_USE_RTP_JITTER_BUFFER:
+                self._report_jitter_buffer_stats()
+        index = self._current_frame_index
+        # 0: post-initialization fmp4 frame
+        # 1: fmp4 initialization segment
+        # 2: bytestream access unit
+        # 3: keyframe
+        is__idr_frame = data[10:11].hex() == KEYFRAME_HEX
+        is_keyframe = is__idr_frame or not is_delta
+        flags = 3 if is_keyframe else 2
+        self._current_frame_index += 1
+
+        if self._encode_for_teleop:
+            self._teleop_data_produced_callback(data, index, flags)
+        if self._telemetry_uploader is not None:
+            self._telemetry_uploader.receive_video_data(data, is__idr_frame, self._input_config.hw_descriptor, self._input_config.ip_location)
+
+    def forward_audio_data(self, data: bytes):
+        if self._telemetry_uploader is not None:
+            self._telemetry_uploader.receive_audio_data(data)
+
+    # APPSRC SUPPORT
+    def feed_image_buffer(self, buf: bytes):
+        if not self._using_appsrc:
+            raise ValueError("Cannot feed_image_buffer: not using appsrc")
+        if not self._is_started:
+            self.start(received_frame=True)
+        if self._is_shutdown:
+            logger.debug("Fed image buffer after encoder is shut down")
+            return
+        if buf == b"":
+            logger.warn("Media encoder received empty buffer")
+            return
+        if (self._loop is not None) and (not self._loop.is_running()):
+            logger.debug("Fed image buffer before loop is running")
+            return
+        if self._pipe is None:
+            logger.debug("Fed image buffer before pipe was created")
+            return
+        if self._src is None:
+            logger.debug("Fed image buffer before src element was created")
+            return
+        if not self._using_appsrc:
+            logger.warn(
+                "feed_image_buffer called on encoder with hardware or rtsp source"
+            )
+            return
+
+        self._frame_count_in_window += 1
+        gst_buf = Gst.Buffer.new_wrapped(buf)
+        if self._pipe.current_state == Gst.State.PLAYING:
+            # Timestamp info can only be collected once frames are already incoming
+            timestamp = self._pipe.get_clock().get_time() - self._pipe.base_time
+            gst_buf.pts = timestamp
+            gst_buf.dts = timestamp
+        self._src.emit("push-buffer", gst_buf)
+
+    # AUDIO SUPPORT
+    def is_audio_setup(self):
+        if self._telemetry_uploader is None:
+            return True
+        return self._telemetry_uploader.is_audio_setup()
+
+    def setup_audio(self, format_string=None, num_channels=None, sample_rate=None):
+        if self._telemetry_uploader is not None:
+            self._telemetry_uploader.setup_audio(
+                format_string=format_string,
+                num_channels=num_channels,
+                sample_rate=sample_rate,
+            )
+
+    def get_aspect_ratio(self):
+        if self._input_config.video_config is None:
+            return None
+        return self._input_config.video_config.get_aspect_ratio()
+
+
+def _has_accelerated_elements() -> bool:
+    for _ in ["nvvidconv", "nvv4l2h264enc"]:
+        try:
+            subprocess.check_call(["gst-inspect-1.0", _])
+        except subprocess.CalledProcessError as e:
+            if e.returncode == 255:
+                return False
+    return True
+
+
+def _convert_bitrate_for_jetson(bitrate: int) -> int:
+    if bitrate < 512:
+        b = bitrate // 10
+        return b * 10000
+    b = bitrate // 100
+    return b * 100000
+
+
+def _nvv4l2h264enc_has_idrinterval() -> bool:
+    try:
+        result = subprocess.check_output(["gst-inspect-1.0", "nvv4l2h264enc"])
+        print(str(result))
+        if "idrinterval" in str(result):
+            return True
+    except subprocess.CalledProcessError as e:
+        if e.returncode == 255:
+            return False
+    return False
+
+
+def get_hardware_formats(hw_descriptor: Optional[str]) -> Optional[str]:
+    if hw_descriptor is None:
+        return None
+    try:
+        return str(
+            subprocess.check_output(
+                ["v4l2-ctl", "-d", hw_descriptor, "--list-formats-ext"]
+            )
+        )
+    except Exception:
+        return None
